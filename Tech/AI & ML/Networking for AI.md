# Explore More
* Interconnect within RACK:
	* Nvidia NVLink
	* UALink (Open standard)
* Scale out level:
	* InfiniBand vs Ethernet
	* Ultra Ethernet Consortium working on UET protocol
* Architectural swift for AI Computing from server based loads to integrated rack scale systems eg. Nvidia GB200 NVL200 platform and AWS Trainium2 Ultraserver.
* Networking vendors include classics Cisco, Juniper, Arista & Nokia along with startups like Arrcus and DriveNets
	* All are exploring new networking technologies like Cell based switching
	* Data Center Interconnect (DCI) is expanding to adopt 400ZR and 800ZR solutions for distributed AI training.
* AI accelerators
	* GPU vs NPU vs LPU (collectively xPU)
* AI Players:
	* OpenAI's ChatGPT (GPT4 family)
	* Google's Gemini
	* Anthropic's Claude
	* xAI's Grok
	* Meta's Llama family
	* Mistral's Le Chat
	* Alibaba's Qwen
	* DeepSeek-R1 (from Chinese hedge fund High-Flyer-backed)
* xPU based data center providers:
	* CoreWeave
	* Lambda
	* Crusoe

# Opportunity Vectors
## Power Consumption / Optimization
* 20 GW additional power consumption for Data Center in 2025
* 47 GW addition power estimated by Goldman Sachs through 2030*