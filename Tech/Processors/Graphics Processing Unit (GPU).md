# What is it?
A [GPU, or graphics processing unit](https://blog.purestorage.com/purely-informational/cpu-vs-gpu-for-machine-learning/), is a more recognizable piece of hardware, a specialized component engineered to handle demanding graphics-rendering tasks. Although they were originally designed for processing imagery output to a display device, their capacity for computationally intensive operations has led to many more applications, extending their use to artificial intelligence and scientific computing. 

GPUs excel in [parallel workloads](https://blog.purestorage.com/purely-informational/parallel-vs-distributed-computing-an-overview/), providing the results of thousands of small computations nearly instantaneously. This parallel workload strength has recently made GPUs indispensable in tasks that require [data parallelism](https://www.purestorage.com/knowledge/what-is-data-parallelism.html) like image processing, simulations and machine learning. 

Architecturally speaking, high-end GPUs can have thousands of cores, from which they get their strength at processing computations across a vast number of processing elements in tandem. This has made them increasingly valuable in AI, where they’ve been used to train and deploy [deep learning models](https://blog.purestorage.com/purely-informational/deep-learning-vs-machine-learning/). Parallel processing accelerates complex [neural network training](https://www.purestorage.com/knowledge/what-is-neural-processing-unit.html).

GPUs are also highly versatile, adapting to various architectures and supporting a wide spectrum of training models. Their parallel architecture combined with their high-speed memory and optimized data throughput, and advanced memory management techniques means GPUs can process large volumes of data when storage solutions are optimally configured.